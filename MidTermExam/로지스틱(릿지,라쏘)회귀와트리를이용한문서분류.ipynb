{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09ee14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이거 import하는거 아직 못외움\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc010286",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism','talk.religion.misc','comp.graphics','sci.space']\n",
    "train = fetch_20newsgroups(subset='train',remove = ['headers','footers','quotes'],categories = categories)\n",
    "test = fetch_20newsgroups(subset='test',remove = ['headers','footers','quotes'],categories = categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7024e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.data\n",
    "y_train = train.target\n",
    "X_test = test.data\n",
    "y_test = test.target\n",
    "train_target_names = train.target_names\n",
    "test_target_names = test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae2ecb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       ...,\n",
       "       [0.       , 0.       , 0.       , ..., 0.2224066, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , ..., 0.       , 0.       ,\n",
       "        0.       ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features =2000,max_df = 0.5,min_df = 5)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa049fbc",
   "metadata": {},
   "source": [
    "# Logistic회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e56f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score 0.9296951819075713\n",
      "test_score 0.7339246119733924\n"
     ]
    }
   ],
   "source": [
    "# sklearn이 제공하는 logistic regression을 사용\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# count vector에 대해 regression을 해서 NB 와 비교\n",
    "LR_clf = LogisticRegression()\n",
    "LR_clf.fit(X_train_tfidf,y_train)\n",
    "\n",
    "print(\"train_score\",LR_clf.score(X_train_tfidf,y_train))\n",
    "print(\"test_score\",LR_clf.score(X_test_tfidf,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e16e22d",
   "metadata": {},
   "source": [
    "* 나이브 베이즈보다 성능이 떨어지는 것을 확인할 수 있다. \n",
    "    * 첫째 이유는 나이브 베이즈의 가정이 텍스트 분류 환경과 잘맞고\n",
    "    * 로지스틱 회귀 분석에서 과적합이 일어났기 때문이다.\n",
    "    \n",
    "* 과적합을 방지하는 방법으로는 두가지 방법이 있다.\n",
    "    * 첫째 특성의 수를 줄이는 것\n",
    "    * 정규화를 이용해 각 특성에 대한 계수가 지나치게 커지는 것을 막는 방법\n",
    "        * Ridge회귀(L2(제곱)회귀)와 Lasso회귀(L1(절대값)회귀)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d718f7",
   "metadata": {},
   "source": [
    "# 릿지회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d23ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.960\n",
      "Test set score: 0.735\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런의 RidgeClassifier 이용\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "# 릿지 분류기 선언\n",
    "ridge_clf = RidgeClassifier() # ... 이 부분을 완성하시오\n",
    "# 학습\n",
    "ridge_clf.fit(X_train_tfidf, y_train) # ... 이 부분을 완성하시오\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1276bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_features(classifier, vectorizer, categories):\n",
    "    # 단어집합을 array로 만들어놓음\n",
    "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "    for i, category in enumerate(categories):\n",
    "        # 역순으로 정렬하기 위해 계수에 음수를 취해서 정렬 후 앞에서부터 10개의 값을 반환\n",
    "        # categories와 naive classifier에서는 각각의 count vector의 feature들의 계수\n",
    "        top10 = np.argsort(-classifier.coef_[i])[:10] # 내림차순 정렬 해서 상위 10개 뽑음\n",
    "        # 카테고리에 영향이 큰 특성 10개를 출력\n",
    "        print(\"{0}: {1}\".format(category, \", \".join(feature_names[top10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa707a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: bobby, religion, atheists, atheism, motto, punishment, satan, deletion, islamic, liar\n",
      "comp.graphics: graphics, computer, 3d, file, 42, hi, image, using, screen, looking\n",
      "sci.space: space, orbit, spacecraft, sci, moon, funding, nasa, 23, engineering, nick\n",
      "talk.religion.misc: christian, blood, christians, fbi, order, objective, hudson, children, abortion, dead\n"
     ]
    }
   ],
   "source": [
    "# def top10_features(classifier, vectorizer, categories): 를 이용하여 top10 feature를 확인하시오\n",
    "top10_features(ridge_clf, tfidf, train.target_names) # ... 이 부분을 완성하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d03fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13653463,  0.27392561, -0.17542034, ..., -0.5976059 ,\n",
       "        -0.13816128, -0.08897165],\n",
       "       [ 0.18961568, -0.17999103,  0.71643096, ..., -0.02634002,\n",
       "        -0.07464021,  0.21999342],\n",
       "       [ 0.16238766,  0.01501701, -0.44297895, ..., -0.29413289,\n",
       "         0.08429874, -0.14569065],\n",
       "       [-0.21589384, -0.10933962, -0.09857503, ...,  0.9168149 ,\n",
       "         0.12875138,  0.01548144]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecc0fa",
   "metadata": {},
   "source": [
    "* 과적합이 더 심해졌음을 확인할 수 있다.\n",
    "    * 이를 해결하기 위해선 최적의 alpha값을 선택하여야 하는데, 이를 위해서 검증 데이터셋을 도입할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4f32aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 8:2의 비율로 나누기\n",
    "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42) # ... 이 부분을 완성하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9725152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7248157248157249"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... 이 부분을 완성하시오 (전체 코드 작성)\n",
    "# 설명: train에 대해 학습하고, validation에 대한 score를 재는 코드를 작성하시오.\n",
    "\n",
    "# 1. alpha=0.1인 분류기 선언\n",
    "ridge_clf = RidgeClassifier(alpha = 0.1)\n",
    "# 2. X_train_ridge에 대해 학습\n",
    "ridge_clf.fit(X_train_ridge,y_train_ridge)\n",
    "# 3. X_val_ridge에 대해 score 확인\n",
    "score = ridge_clf.score(X_val_ridge,y_val_ridge)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d28364ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7248157248157249\n",
      "0.7714987714987716\n",
      "0.7862407862407862\n",
      "0.800982800982801\n",
      "0.8058968058968059\n",
      "0.800982800982801\n",
      "0.8034398034398035\n",
      "0.8083538083538083\n",
      "0.8083538083538083\n",
      "0.8132678132678133\n",
      "0.8157248157248157\n",
      "0.8206388206388207\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8255528255528255\n",
      "0.8255528255528255\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8206388206388207\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8230958230958231\n",
      "0.8157248157248157\n",
      "0.8157248157248157\n",
      "0.8157248157248157\n",
      "0.8157248157248157\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n",
      "0.8083538083538083\n",
      "0.8083538083538083\n",
      "0.8034398034398035\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.7985257985257985\n",
      "0.7985257985257985\n",
      "0.7985257985257985\n",
      "0.7985257985257985\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.8034398034398035\n",
      "0.8034398034398035\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.800982800982801\n",
      "0.7985257985257985\n",
      "0.7985257985257985\n",
      "0.7960687960687961\n",
      "0.7960687960687961\n",
      "0.7960687960687961\n",
      "0.7960687960687961\n",
      "0.7936117936117936\n",
      "0.7936117936117936\n",
      "0.7936117936117936\n",
      "0.7911547911547911\n",
      "0.7911547911547911\n",
      "0.7886977886977887\n",
      "0.7862407862407862\n",
      "0.7862407862407862\n",
      "0.7862407862407862\n",
      "0.7862407862407862\n",
      "0.7837837837837838\n",
      "0.7813267813267813\n",
      "0.7813267813267813\n",
      "0.7788697788697788\n",
      "0.7788697788697788\n",
      "0.7788697788697788\n",
      "0.7788697788697788\n",
      "0.7813267813267813\n",
      "0.7813267813267813\n",
      "0.7813267813267813\n",
      "0.7813267813267813\n",
      "0.7813267813267813\n",
      "0.7788697788697788\n",
      "0.7788697788697788\n",
      "0.7788697788697788\n",
      "0.7788697788697788\n",
      "0.7764127764127764\n",
      "0.773955773955774\n",
      "0.773955773955774\n",
      "0.7714987714987716\n",
      "0.7714987714987716\n",
      "0.773955773955774\n",
      "0.769041769041769\n",
      "0.769041769041769\n",
      "0.769041769041769\n",
      "0.7665847665847666\n",
      "0.7665847665847666\n"
     ]
    }
   ],
   "source": [
    "# ... 이 부분을 완성하시오 (전체 코드 작성)\n",
    "# 설명: alpha를 0.1부터 10까지 0.1씩 증가시켜 학습시키고, score를 확인하는 코드를 작성하시오.\n",
    " # (hint: np.arange(start, stop, step))\n",
    "# 위의 코드에서 alpha=0.1을 변경시켜가면서 score 값을 확인\n",
    "import numpy as np\n",
    "# 1. for 문 작성\n",
    "for alpha in np.arange(0.1, 10, 0.1):\n",
    "    # 2. 위의 코드 3줄 복사\n",
    "    ridge_clf = RidgeClassifier(alpha = alpha)\n",
    "    # 2. X_train_ridge에 대해 학습\n",
    "    ridge_clf.fit(X_train_ridge,y_train_ridge)\n",
    "    # 3. X_val_ridge에 대해 score 확인\n",
    "    score = ridge_clf.score(X_val_ridge,y_val_ridge)\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf6a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max alpha 1.600 at max validation score 0.826\n"
     ]
    }
   ],
   "source": [
    "# ... 이 부분을 완성하시오 (전체 코드 작성)\n",
    "# alpha를 0.1부터 10까지 0.1씩 증가시키면서, score 값을 최대로 만드는 alpha 값을 max_alpha에 저장하시오\n",
    "# 위의 코드에서 score 값을 비교하여 저장하는 코드 추가\n",
    "\n",
    "# 1. max_alpha 초기값 선언\n",
    "max_alpha = 0\n",
    "max_score = 0\n",
    "# 2. for 문 작성\n",
    "    # 3. 위의 코드 3줄 복사\n",
    "    # 4. if 문을 통한 비교\n",
    "        # 5. max_alpha 저장\n",
    "\n",
    "for alpha in np.arange(0.1, 10, 0.1):\n",
    "    # 2. 위의 코드 3줄 복사\n",
    "    ridge_clf = RidgeClassifier(alpha = alpha)\n",
    "    # 2. X_train_ridge에 대해 학습\n",
    "    ridge_clf.fit(X_train_ridge,y_train_ridge)\n",
    "    # 3. X_val_ridge에 대해 score 확인\n",
    "    score = ridge_clf.score(X_val_ridge,y_val_ridge)\n",
    "    if score>max_score:\n",
    "        max_alpha = alpha\n",
    "        max_score = score\n",
    "\n",
    "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed62af1",
   "metadata": {},
   "source": [
    "* 위의 그리드 서치 방식으로 최적의 알파값을 구했으므로 이를 이용해서 test데이터 셋에 대해서 최종 정확도를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d09f6101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.948\n",
      "Test set score: 0.739\n"
     ]
    }
   ],
   "source": [
    "# 릿지 분류기 선언\n",
    "# 위의 셀에서 얻은 최대 alpha 값을 이용하시오\n",
    "ridge_clf = RidgeClassifier(alpha=1.6) # ... 이 부분을 완성하시오\n",
    "ridge_clf.fit(X_train_tfidf, y_train) # 학습\n",
    "\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd2b2f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism: bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
      "comp.graphics: graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
      "sci.space: space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
      "talk.religion.misc: christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
     ]
    }
   ],
   "source": [
    "top10_features(ridge_clf, tfidf, train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cdaccb",
   "metadata": {},
   "source": [
    "## 라쏘회귀\n",
    "-> 라쏘회귀는 사이킷런의 LogisticRegression에서 `penalty`파라미터를 `l1`으로 지정함으로써 구현할 수 있다.<br>\n",
    "-> 동시에 정규화정도인 C를 선택해야하고<br>\n",
    "-> solver = 'liblinear'를 선택해줘야 한다.<br>\n",
    "* 라쏘회귀는 어떤 특성의 계수가 0에 가까워지면 이를 완전히 0으로 바꾼다는 점에서 차이가 있다\n",
    "* 하지만 라쏘는 정규화를 통해 과적합을 줄이지만 동시에 특성의 수도 줄어들기 때문에 성능이 향상된다고 보기는 어렵다.\n",
    "\n",
    "**Lasso와 같이 특성의 수를 줄이는 것을 특성 선택이라고 한다. 특성을 줄임으로써 얻는 장점은 연관성이 떨어지는 특성을 배제하고 중요한 특성을 집중할 수 있다는 것이다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "005f4a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.8185840707964602\n",
      "test:  0.7235772357723578\n"
     ]
    }
   ],
   "source": [
    "lasso_clf= LogisticRegression(penalty='l1',solver = 'liblinear',C=1)\n",
    "lasso_clf.fit(X_train_tfidf,y_train)\n",
    "print(\"train: \",lasso_clf.score(X_train_tfidf,y_train))\n",
    "print(\"test: \",lasso_clf.score(X_test_tfidf,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79bcff1",
   "metadata": {},
   "source": [
    "## 결정트리를 이용한 기타 문서 분류방법\n",
    "* 사이킷런은 결정트리를 위한 DecisionClassifier클래스와, RandomForestClassifier클래스, 그래디언트 부스팅을 지원하는 GradientBoostingClassifier를 지원한다.\n",
    "* 결정트리는 학습데이터에 과적합이 되는 성향이 매우 강한데, 문서분류의 겨우 전반적으로 결정트리 기반의 알고리즘이 좋은 성능을 보여주지 못한다.\n",
    "    * 결정트리의 feature_importances_는 Training set의 column의 순서에 따라서 부여되게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fe8db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Decision Tree train set score: 0.977\n",
      "#Decision Tree test set score: 0.536\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=7)\n",
    "tree.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
    "print('#Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eea7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Random Forest train set score: 0.977\n",
      "#Random Forest test set score: 0.685\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(random_state=7)\n",
    "forest.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))\n",
    "print('#Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab94e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Gradient Boosting train set score: 0.933\n",
      "#Gradient Boosting test set score: 0.696\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier(random_state=7)\n",
    "gb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))\n",
    "print('#Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f23c162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.00018793, ..., 0.00321606, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93830b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, christian: 0.010, looking: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
     ]
    }
   ],
   "source": [
    "sorted_feature_importances = sorted(zip(tfidf.get_feature_names_out(), gb.feature_importances_), key=lambda x: x[1], reverse=True)\n",
    "for feature, value in sorted_feature_importances[:40]:\n",
    "    print('%s: %.3f' % (feature, value), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce2c23",
   "metadata": {},
   "source": [
    "# [[실습 4-2-1]]\n",
    "# coef_의 결과와 feature_importances_ 결과 비교를 통해, 회귀분석 방법과 트리 기반의 분류 방식의 차이점 알아보기\n",
    "* coef_의 결과(여러 분류기 중 1개 이상)와 feature_importances_ 결과(여러 분류기 중 1개 이상) 복사/붙여넣기\n",
    "* 비교를 통해 어떤 차이점이 있는 것 같은지 분석해보시오.\n",
    "> 결정트리에서는 성격이 비슷한 두 단어 중 하나가 분류에 먼저 사용되면 다른 단어는 상대적으로 중요도가 떨어지게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca8592f",
   "metadata": {},
   "source": [
    "## 한국어 문서의 분류\n",
    "* 영어 문서는 사이킷런에서 제공하는 기본 토크나이저(CountVectorizer,TfidfVectorizer)를 사용할 수 있었으나, 한글 문서는 처음부터 별도의 토크나이저를 쓸 수 밖에 없다.\n",
    "\n",
    "### 입력 값으로 리뷰가 들어오면, 어떤 영화에 대한 리뷰인지 예측하는 알고리즘을 만들어 보자!\n",
    "**&rightarrow; 앞에서는 영화리뷰를 통해서 영화간의 유사도를 비교하였지만, 여기서는 이제 영화리뷰를 이용해서 영화의 제목을 예측하는 분류기를 만들어보자**\n",
    "* '신과함께, 택시운전사, 인피니티 워, 범죄도시, 곤지암, 라라랜드, 코코' 중 하나로 분류\n",
    "* **입력**: 몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.\n",
    "* **출력**: 인피니티 워"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e8b72e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
       "      <td>1</td>\n",
       "      <td>2018.10.29</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.26</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.24</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
       "      <td>8</td>\n",
       "      <td>2018.10.22</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>재미있다</td>\n",
       "      <td>10</td>\n",
       "      <td>2018.10.20</td>\n",
       "      <td>인피니티 워</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating        date  \\\n",
       "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
       "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
       "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
       "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
       "4                                               재미있다      10  2018.10.20   \n",
       "\n",
       "    title  \n",
       "0  인피니티 워  \n",
       "1  인피니티 워  \n",
       "2  인피니티 워  \n",
       "3  인피니티 워  \n",
       "4  인피니티 워  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./daum_movie_review.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f418ead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "신과함께      4947\n",
       "택시운전사     2322\n",
       "인피니티 워    2042\n",
       "범죄도시      1939\n",
       "곤지암       1547\n",
       "라라랜드      1150\n",
       "코코         778\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0591cab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set size: 11043\n",
      "#Test set size: 3682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨\n",
    "# train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)를 참고\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review,df.title, random_state=0) # ... 이 부분을 완성하시오\n",
    "\n",
    "print('#Train set size:', len(X_train)) # 실제로 몇개의 특성이 사용되었는지 확인\n",
    "print('#Test set size:', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b62f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
      "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt # konlpy에서 Twitter 형태소 분석기를 import\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "print(okt.morphs(X_train[1])) # 둘째 리뷰에 대해 형태소 단위로 tokenize\n",
    "print(okt.nouns(X_train[1])) # 둘째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd74a8",
   "metadata": {},
   "source": [
    "* 일반적으로 문서를 대상으로 분류를 하는 경우에는 명사만으로도 좋은 결과를 보이는 경우가 많으므로 우선 Okt.nouns를 tokenizer로 사용해서 카운트벡터를 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f8ea01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 약간의 시간이 소요됩니다! (약 1분 30초)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Okt 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# mytokenizer를 okt.nouns로 여기선 사용함\n",
    "# mytokenizer를 사용하면 그때 그때 호출해야해서오래걸림\n",
    "tfidf = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ab66045",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd3f2133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.756\n",
      "#Test set score: 0.694\n"
     ]
    }
   ],
   "source": [
    "# logistic regression 분류기 선언\n",
    "# 충분한 학습을 위해서 max_iter=1000으로 설정\n",
    "# 기본값은 100인데 100으로 돌리면 충분히 수렴되지 않았다는 warning이 발생하게 된다.\n",
    "LR_clf = LogisticRegression(max_iter = 1000)\n",
    "# 분류기 학습\n",
    "LR_clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train))) # train data 예측정확도\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test))) # test data 예측정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6228a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "곤지암: 공포영화, 공포, 귀신, 곤지암, 무서움, 소리, 기담, 개, 공포물, 장난\n",
      "라라랜드: 음악, 뮤지컬, 꿈, 사랑, 노래, 엔딩, 여운, 인생, 재즈, 환상\n",
      "범죄도시: 마동석, 윤계상, 조선족, 액션, 조연, 조폭, 범죄, 마블리, 형사, 폭력\n",
      "신과함께: 원작, 차태현, 웹툰, 신파, 김동욱, 판타지, 신, 천만, 지옥, 하정우\n",
      "인피니티 워: 마블, 노스, 어벤져스, 히어로, 번역, 토르, 편, 결말, 다음, 영웅\n",
      "코코: 디즈니, 애니, 겨울왕국, 감동, 코코, 픽사, 애니메이션, 가족, 어른, 노래\n",
      "택시운전사: 광주, 송강호, 역사, 전두환, 택시, 가슴, 진실, 민주주의, 감동, 추격\n"
     ]
    }
   ],
   "source": [
    "top10_features(LR_clf, tfidf, sorted(df.title.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcd079c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫 번째 리뷰 텍스트:  오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.\n",
      "특성으로 추출된 토큰:  ['만', '영화', '다음', '더', '영화']\n",
      "예측된 영화 제목:  신과함께\n",
      "실제 영화 제목:  범죄도시\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째 리뷰에 대한 예측 값 살펴보기\n",
    "print('첫 번째 리뷰 텍스트: ', X_test.iloc[0])\n",
    "print('특성으로 추출된 토큰: ', okt.nouns(X_test.iloc[0]))\n",
    "predict = LR_clf.predict(X_test_tfidf[0])\n",
    "print('예측된 영화 제목: ', predict[0])\n",
    "print('실제 영화 제목: ', y_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef3d5576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['신과함께', '범죄도시', '코코', ..., '인피니티 워', '인피니티 워', '신과함께'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd8112fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 영화 제목, 예측한 제목, 리뷰\n",
      "('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')\n",
      "('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')\n",
      "('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')\n",
      "('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')\n",
      "('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')\n",
      "('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')\n",
      "('신과함께', '신과함께', '잠만 자다 왔음')\n",
      "('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')\n",
      "('범죄도시', '신과함께', '잼남')\n",
      "('범죄도시', '인피니티 워', '대박~~')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_839936/568123338.py:2: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  for content in zip(y_test[:10],LR_clf.predict(X_test_tfidf)[:10],X_test[:10]):\n"
     ]
    }
   ],
   "source": [
    "print('실제 영화 제목, 예측한 제목, 리뷰')\n",
    "for content in zip(y_test[:10],LR_clf.predict(X_test_tfidf)[:10],X_test[:10]):\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa615d",
   "metadata": {},
   "source": [
    "# [[실습 4-2-2]]\n",
    "* RidgeClassifier (alpha=0.1)를 이용하여 분류할 경우, Train set score와 Test set score는 얼마인가?\n",
    "* (가능한 경우에만 시도) 이 데이터 셋에서는 valdation에 대한 최적의 alpha는 몇인가? 0.1과 10 사이에서 0.1씩 증가시키며 찾아보시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ebde47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.788\n",
      "test score:0.679\n"
     ]
    }
   ],
   "source": [
    "# 코드를 작성하시오\n",
    "ridge_clf = RidgeClassifier(alpha = 0.1)\n",
    "ridge_clf.fit(X_train_tfidf,y_train)\n",
    "print(\"train score: {:.3f}\".format(ridge_clf.score(X_train_tfidf,y_train)))\n",
    "print(\"test score:{:.3f}\".format(ridge_clf.score(X_test_tfidf,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "913b6188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 alpha 1.1\n",
      "최적 score 0.6962426437301946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection  import train_test_split\n",
    "X2_train,X_val,y2_train,y_val = train_test_split(X_train_tfidf,y_train,test_size = 0.2,random_state = 42)\n",
    "optim_alpha = 0\n",
    "max_score = 0\n",
    "for alpha in np.arange(0.1,10,0.1):\n",
    "    ridge_clf = RidgeClassifier(alpha = alpha)\n",
    "    ridge_clf.fit(X2_train,y2_train)\n",
    "    score = ridge_clf.score(X_val,y_val)\n",
    "    if score>max_score:\n",
    "        optim_alpha = alpha\n",
    "        max_score = score\n",
    "\n",
    "print(\"최적 alpha\",optim_alpha)\n",
    "print(\"최적 score\",max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c1838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sj_virtual",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
