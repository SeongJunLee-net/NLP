{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Thm_ZG0WcTpC"
   },
   "source": [
    "# [자연어처리]\n",
    "# 7주차(7-1). 차원 축소(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQjjg1vRuQiB"
   },
   "source": [
    "# 201900278 이성준 <- 본인의 학번, 이름으로 변경하여 제출\n",
    "* **모든 셀 실행** 후 제출하시기 바랍니다.\n",
    "* **실습 (7-1-1)**이 있습니다. (제출 기한: 10/17(화) 23시 59분까지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7WXGR9ouSPw"
   },
   "source": [
    "# 이제 Colab 사용에 모든 수강생분들이 어느정도 익숙해 졌을 거라 생각됩니다!\n",
    "> ##### 중간 중간 **'### ... 이 부분을 완성하시오'** 라는 부분의 코드를 완성해야 합니다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "946IVH10vEC3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kd6v5oMZuT8u"
   },
   "source": [
    "## 6주차 수업 내용 리뷰 -시작-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNgIfKg8zWcL"
   },
   "source": [
    "## 6.2 PCA를 이용한 차원 축소\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCb5DPXUGaak"
   },
   "source": [
    "데이터 셋 준비 (우리에게 익숙한 20newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SWco5iOPzWcM"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "#20개의 토픽 중 선택하고자 하는 토픽을 리스트로 생성\n",
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "\n",
    "#학습 데이터셋을 가져옴\n",
    "#메일 내용에서 hint가 되는 부분을 삭제 - 순수하게 내용만으로 분류\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      remove=('headers', 'footers', 'quotes'),\n",
    "                                      categories=categories)\n",
    "#검증 데이터셋을 가져옴\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     remove=('headers', 'footers', 'quotes'),\n",
    "                                     categories=categories)\n",
    "\n",
    "X_train = newsgroups_train.data   #학습 데이터셋\n",
    "y_train = newsgroups_train.target #학습 데이터셋\n",
    "\n",
    "X_test = newsgroups_test.data     #검증 데이터셋\n",
    "y_test = newsgroups_test.target   #검증 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d03KqvJwGe_k"
   },
   "source": [
    "전처리\n",
    "* 토큰화, 불용어처리, 스테밍\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJKk1hCjGYwT",
    "outputId": "4dd444e2-605e-4cf2-fc30-78714a5cb29c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sjlee/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SmkiLmtOGUEj"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "RegTok = RegexpTokenizer(\"[\\w']{3,}\") # 정규포현식으로 토크나이저를 정의\n",
    "english_stops = set(stopwords.words('english')) #영어 불용어를 가져옴\n",
    "stemmer = PorterStemmer() # 스테머로 포터스테머 사용\n",
    "\n",
    "def my_tokenizer(text):\n",
    "    tokens = RegTok.tokenize(text)\n",
    "    # stopwords 제외\n",
    "    words = [word for word in tokens if word not in english_stops]\n",
    "    # portr stemmer 적용\n",
    "    features = [stemmer.stem(token) for token in words]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vwcetq65SOa6",
    "outputId": "c377140e-33d3-4bf8-8b19-a3fc444d96f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 약간의 시간(약 30초)이 소요됩니다.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=my_tokenizer, max_features=2000, min_df=5, max_df=0.5)\n",
    "# 토큰화 외에 아무것도 적용하지 않은 채로 확인\n",
    "tfidf = TfidfVectorizer(tokenizer=my_tokenizer) ### ... 이 부분을 완성하시오\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train set을 변환\n",
    "X_test_tfidf = tfidf.transform(X_test) # test set을 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62cFIpxfIwO0",
    "outputId": "0664a341-89af-4b8a-e30d-013067d1dab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tfidf matrix shape: (2034, 20085)\n"
     ]
    }
   ],
   "source": [
    "print('Original tfidf matrix shape:', X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3C-uLYPbzWcO",
    "outputId": "330822ce-6ab0-4c09-8fcb-800fdd1e5773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tfidf matrix shape: (2034, 20085)\n",
      "PCA Converted matrix shape: (2034, 2000)\n",
      "Sum of explained variance ratio: 1.000\n"
     ]
    }
   ],
   "source": [
    "# 약간의 시간(약 30초)이 소요됩니다.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#  20,085 차원을 2,000 차원으로 축소\n",
    "pca = PCA(n_components=2000, random_state=7) ### ... 이 부분을 완성하시오\n",
    "X_train_pca = pca.fit_transform(X_train_tfidf.toarray())\n",
    "X_test_pca = pca.transform(X_test_tfidf.toarray())\n",
    "\n",
    "print('Original tfidf matrix shape:', X_train_tfidf.shape)\n",
    "print('PCA Converted matrix shape:', X_train_pca.shape)\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(pca.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oW4iq1IzWcO",
    "outputId": "614e1887-6ab2-4c9f-a439-daba5c3afe1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Train set score: 0.962\n",
      "#Test set score: 0.761\n",
      "#Train set score: 0.962\n",
      "#Test set score: 0.761\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_clf = LogisticRegression() #분류기 선언\n",
    "\n",
    "# PCA로 차원 축소된 X 데이터 이용\n",
    "LR_clf.fit(X_train_tfidf, y_train)\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))\n",
    "\n",
    "# PCA로 차원 축소된 X 데이터 이용\n",
    "LR_clf.fit(X_train_pca, y_train) ### ... 이 부분을 완성하시오\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_pca, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_pca, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu0mgpF6uUnn"
   },
   "source": [
    "## 6주차 수업 내용 리뷰 -끝-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5Hw9SDwvFLi"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPBwVvw2u0x9"
   },
   "source": [
    "## 7-1 주차 수업 내용 -시작-\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atiT2bq8cTpJ"
   },
   "source": [
    "## 6.3 LSA를 이용한 차원 축소와 의미 파악\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s97_V7Wo1tUN"
   },
   "source": [
    "* 기존의 DTM이나 DTM에 단어의 중요도에 따른 가중치를 주었던 TF-IDF 행렬은 단어의 의미를 전혀 고려하지 못한다는 단점을 갖고 있었습니다.\n",
    "* LSA는 기본적으로 DTM이나 TF-IDF 행렬에 절단된 SVD(truncated SVD)를 사용하여 차원을 축소시키고, 단어들의 잠재적인 의미를 끌어낸다는 아이디어를 갖고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdpt3zejjxi7"
   },
   "source": [
    "### DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHXTzFRDjw-c",
    "outputId": "3b3bac22-9514-47bc-a1a9-2d0c5a54c9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['먹고', '싶은', '사과'], ['먹고', '싶은', '바나나'], ['길고', '노란', '바나나', '바나나'], ['저는', '과일이', '좋아요']]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    '먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요'\n",
    "]\n",
    "\n",
    "# 각 문서를 공백 기준으로 단어로 분리\n",
    "tokenized_corpus = [doc.split() for doc in corpus]\n",
    "print(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'먹고': 3,\n",
       " '싶은': 6,\n",
       " '사과': 5,\n",
       " '바나나': 4,\n",
       " '길고': 1,\n",
       " '노란': 2,\n",
       " '저는': 7,\n",
       " '과일이': 0,\n",
       " '좋아요': 8}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "vocabulary = cv.fit_transform(corpus)\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OixVAbctknEr",
    "outputId": "2fbda7f1-6a08-46d3-ef43-110cae8b7ca2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']\n",
      "{'과일이': 0, '길고': 1, '노란': 2, '먹고': 3, '바나나': 4, '사과': 5, '싶은': 6, '저는': 7, '좋아요': 8}\n"
     ]
    }
   ],
   "source": [
    "# 모든 단어들의 집합 생성 후 가나다 순으로 정렬\n",
    "vocabulary = sorted(set(word for doc in tokenized_corpus for word in doc))\n",
    "print(vocabulary)\n",
    "\n",
    "# 단어와 인덱스를 맵핑한 딕셔너리 생성\n",
    "word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "erc4tt4wknG4",
    "outputId": "6d2ea695-099a-4a31-a6ce-9d7e6e554aa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
      "[0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
      "[0, 1, 1, 0, 2, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 빈도수 계산\n",
    "word_frequency = []\n",
    "for doc in tokenized_corpus:\n",
    "    frequency = [0] * len(vocabulary)\n",
    "    for word in doc:\n",
    "        if word in word2idx:\n",
    "            frequency[word2idx[word]] += 1\n",
    "    word_frequency.append(frequency)\n",
    "\n",
    "for freq in word_frequency:\n",
    "    print(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xuACOS6ylHVI"
   },
   "source": [
    "### sklearn의 CountVectorizer를 이용한 DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4Wy2HV4zaeZ",
    "outputId": "f6be7771-ba70-499d-bca2-15469acd736f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'먹고': 3, '싶은': 6, '사과': 5, '바나나': 4, '길고': 1, '노란': 2, '저는': 7, '과일이': 0, '좋아요': 8}\n",
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    '먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요'\n",
    "]\n",
    "\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
    "A = vector.fit_transform(corpus).toarray()\n",
    "\n",
    "# 각 단어와 맵핑된 인덱스 출력\n",
    "print(vector.vocabulary_)\n",
    "print(A)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9byyZNe0hTm"
   },
   "source": [
    "### Full SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDutZy3u1ZZP"
   },
   "source": [
    "* 4 × 9의 크기를 가지는 DTM이 생성되었습니다.\n",
    "* 이에 대해서 풀 SVD(full SVD)를 수행해보겠습니다.\n",
    "    * 단, 여기서는 대각 행렬의 변수명을 Σ가 아니라 S를 사용합니다.\n",
    "    * 또한 V의 전치 행렬을 VT라고 하겠습니다.\n",
    "    * 소수점의 길이가 너무 길게 출력하면 보기 힘들어서 두번째 자리까지만 출력하기위해서 .round(2)를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "43wXmxxez7Qq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "U, s, VT = np.linalg.svd(A, full_matrices = True) # 전체 매트릭스를 만들어달라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6r2rt5wI0Q2n",
    "outputId": "4e7f044c-2c91-4b85-c033-4758e458404a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 U :\n",
      "[[-0.24  0.75  0.   -0.62]\n",
      " [-0.51  0.44 -0.    0.74]\n",
      " [-0.83 -0.49 -0.   -0.27]\n",
      " [-0.   -0.    1.    0.  ]]\n",
      "행렬 U의 크기(shape) : (4, 4)\n"
     ]
    }
   ],
   "source": [
    "print('행렬 U :')\n",
    "print(U.round(2))\n",
    "print('행렬 U의 크기(shape) :',np.shape(U))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6DdED2q1WHL"
   },
   "source": [
    "* 4 × 4의 크기를 가지는 직교 행렬 U가 생성되었습니다.\n",
    "* 이제 대각 행렬 S를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whwmlvcy0TwW",
    "outputId": "1b3f561e-7d0b-4afc-d5d4-9c05c3e2d878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특이값 벡터 :\n",
      "[2.69 2.05 1.73 0.77]\n",
      "특이값 벡터의 크기(shape) : (4,)\n"
     ]
    }
   ],
   "source": [
    "print('특이값 벡터 :')\n",
    "print(s.round(2))\n",
    "print('특이값 벡터의 크기(shape) :',np.shape(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LjiVpLw1hu9"
   },
   "source": [
    "* Numpy의 linalg.svd()는 특이값 분해의 결과로 대각 행렬이 아니라 특이값의 리스트를 반환합니다.\n",
    "* 그러므로 앞서 본 수식의 형식으로 보려면 이를 다시 대각 행렬로 바꾸어 주어야 합니다.\n",
    "* 우선 특이값을 s에 저장하고 대각 행렬 크기의 행렬을 생성한 후에 그 행렬에 특이값을 삽입해도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqP6HS_U1EPD",
    "outputId": "5f0926a7-f2e0-45cb-a734-3657dbc6b786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대각 행렬 S :\n",
      "[[2.69 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   2.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   1.73 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.77 0.   0.   0.   0.   0.  ]]\n",
      "대각 행렬의 크기(shape) :\n",
      "(4, 9)\n"
     ]
    }
   ],
   "source": [
    "# 대각 행렬의 크기인 4 x 9의 임의의 행렬 생성\n",
    "S = np.zeros((4, 9))\n",
    "\n",
    "# 특이값을 대각행렬에 삽입\n",
    "S[:4, :4] = np.diag(s)\n",
    "\n",
    "print('대각 행렬 S :')\n",
    "print(S.round(2))\n",
    "\n",
    "print('대각 행렬의 크기(shape) :')\n",
    "print(np.shape(S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w283FcEC1kv7"
   },
   "source": [
    "* 4 × 9의 크기를 가지는 대각 행렬 S가 생성되었습니다.\n",
    "* 2.69 > 2.05 > 1.73 > 0.77 순으로 값이 내림차순을 보이는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jusQppK20TzP",
    "outputId": "9b328c50-8b67-4476-98c5-57dff8792302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직교행렬 VT :\n",
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]\n",
      " [ 0.58 -0.    0.    0.   -0.    0.   -0.    0.58  0.58]\n",
      " [ 0.   -0.35 -0.35  0.16  0.25 -0.8   0.16 -0.   -0.  ]\n",
      " [-0.   -0.78 -0.01 -0.2   0.4   0.4  -0.2   0.    0.  ]\n",
      " [-0.29  0.31 -0.78 -0.24  0.23  0.23  0.01  0.14  0.14]\n",
      " [-0.29 -0.1   0.26 -0.59 -0.08 -0.08  0.66  0.14  0.14]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19  0.75 -0.25]\n",
      " [-0.5  -0.06  0.15  0.24 -0.05 -0.05 -0.19 -0.25  0.75]]\n",
      "직교 행렬 VT의 크기(shape) :\n",
      "(9, 9)\n"
     ]
    }
   ],
   "source": [
    "print('직교행렬 VT :')\n",
    "print(VT.round(2))\n",
    "\n",
    "print('직교 행렬 VT의 크기(shape) :')\n",
    "print(np.shape(VT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLvFbEDr1nNk"
   },
   "source": [
    "* 9 × 9의 크기를 가지는 직교 행렬 VT(V의 전치 행렬)가 생성되었습니다.\n",
    "<br><br>\n",
    "* 이제 U × S × VT를 하면 기존의 행렬 A가 나와야 합니다.\n",
    "* Numpy의 allclose()는 2개의 행렬이 동일하면 True를 리턴합니다.\n",
    "    * 이를 사용하여 정말로 기존의 행렬 A와 동일한지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "avhJ-UFX1Lgj",
    "outputId": "67d11665-b3cd-4879-d52a-fd56de217920"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(A, np.dot(np.dot(U,S), VT).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "phTwopdVNgR1",
    "outputId": "3445c198-50a7-4d4f-a22b-310b7c1d70be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.05932925e-17,  1.67304430e-16,  1.67304430e-16,\n",
       "         1.00000000e+00,  1.01480261e-16,  1.00000000e+00,\n",
       "         1.00000000e+00,  9.05932925e-17,  9.05932925e-17],\n",
       "       [ 1.50768414e-16, -4.34272465e-17, -4.34272465e-17,\n",
       "         1.00000000e+00,  1.00000000e+00, -2.81993395e-16,\n",
       "         1.00000000e+00, -1.35889939e-16, -1.35889939e-16],\n",
       "       [ 8.85941242e-17,  1.00000000e+00,  1.00000000e+00,\n",
       "        -1.73647539e-16,  2.00000000e+00, -4.01831990e-16,\n",
       "        -1.73647539e-16,  1.13241616e-16,  1.13241616e-16],\n",
       "       [ 1.00000000e+00, -6.53163860e-17,  1.30880556e-16,\n",
       "         2.85369307e-16, -4.94463296e-17,  1.98446461e-16,\n",
       "        -9.92232303e-17,  1.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(U,S), VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBJGXTBT0j4C"
   },
   "source": [
    "### Truncated SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMfX9jr31poZ"
   },
   "source": [
    "* 지금까지 수행한 것은 풀 SVD(Full SVD)입니다.\n",
    "* 이제 t를 정하고, 절단된 SVD(Truncated SVD)를 수행해보도록 합시다. 여기서는 t=2로 하겠습니다.\n",
    "* 우선 대각 행렬 S 내의 특이값 중에서 상위 2개만 남기고 제거해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsPgkMFr0dSl",
    "outputId": "0fb9fdcf-f995-467e-d98f-4d7c779ec203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대각 행렬 S :\n",
      "[[2.69 0.  ]\n",
      " [0.   2.05]]\n"
     ]
    }
   ],
   "source": [
    "# 특이값 상위 2개만 보존\n",
    "S = S[:2,:2] ### ... 이 부분을 완성하시오\n",
    "\n",
    "print('대각 행렬 S :')\n",
    "print(S.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oj926yZ81zDk"
   },
   "source": [
    "* 상위 2개의 값만 남기고 나머지는 모두 제거된 것을 볼 수 있습니다.\n",
    "* 이제 직교 행렬 U에 대해서도 2개의 열만 남기고 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4GhPADcY0T2F",
    "outputId": "308a339b-2441-4db9-afdb-5483adb4e93e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 U :\n",
      "[[-0.24  0.75]\n",
      " [-0.51  0.44]\n",
      " [-0.83 -0.49]\n",
      " [-0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "U = U[:,:2] ### ... 이 부분을 완성하시오\n",
    "print('행렬 U :')\n",
    "print(U.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWA3Svrj14Lw"
   },
   "source": [
    "* 2개의 열만 남기고 모두 제거가 된 것을 볼 수 있습니다.\n",
    "* 이제 행렬 V의 전치 행렬인 VT에 대해서 2개의 행만 남기고 제거합니다.\n",
    "* 이는 V관점에서는 2개의 열만 남기고 제거한 것이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rd0YmBzw11ts",
    "outputId": "cab1aa6c-f793-4771-aeb3-e27f357166b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "직교행렬 VT :\n",
      "[[-0.   -0.31 -0.31 -0.28 -0.8  -0.09 -0.28 -0.   -0.  ]\n",
      " [ 0.   -0.24 -0.24  0.58 -0.26  0.37  0.58 -0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "VT = VT[:2,:] ### ... 이 부분을 완성하시오\n",
    "print('직교행렬 VT :')\n",
    "print(VT.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YusnY5yl18FV"
   },
   "source": [
    "* 이제 축소된 행렬 U, S, VT에 대해서 다시 U × S × VT연산을 하면 기존의 A와는 다른 결과가 나오게 됩니다.\n",
    "* 값이 손실되었기 때문에 이 세 개의 행렬로는 이제 기존의 A행렬을 복구할 수 없습니다.\n",
    "* U × S × VT연산을 해서 나오는 값을 A_prime이라 하고 기존의 행렬 A와 값을 비교해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oB2_R_ir112h",
    "outputId": "0b0f5bec-5a2a-4ff3-a2ba-b2292d182d08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]]\n",
      "[[ 0.   -0.17 -0.17  1.08  0.12  0.62  1.08 -0.   -0.  ]\n",
      " [ 0.    0.2   0.2   0.91  0.86  0.45  0.91  0.    0.  ]\n",
      " [ 0.    0.93  0.93  0.03  2.05 -0.17  0.03  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.    0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "A_prime = np.dot(np.dot(U,S), VT)\n",
    "print(A)\n",
    "print(A_prime.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XTUfzsx2ABh"
   },
   "source": [
    "* 대체적으로 기존에 0인 값들은 0에 가가운 값이 나오고, 1인 값들은 1에 가까운 값이 나오는 것을 볼 수 있습니다.\n",
    "* 또한 값이 제대로 복구되지 않은 구간도 존재해보입니다.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-TlsOCb3vyO"
   },
   "source": [
    "### [차원 축소된 U, S, VT의 크기의 의미]\n",
    "* 축소된 U는 4 × 2의 크기를 가지는데, 이는 잘 생각해보면 문서의 개수 × 토픽의 수 t의 크기입니다.\n",
    "    * 단어의 개수인 9는 유지되지 않는데 문서의 개수인 4의 크기가 유지되었으니 4개의 문서 각각을 2개의 값으로 표현하고 있습니다.\n",
    "    * 즉, U의 각 행은 잠재 의미를 표현하기 위한 수치화 된 각각의 문서 벡터라고 볼 수 있습니다.\n",
    "* 축소된 VT는 2 × 9의 크기를 가지는데, 이는 잘 생각해보면 토픽의 수 t × 단어의 개수의 크기입니다.\n",
    "    * VT의 각 열은 잠재 의미를 표현하기 위해 수치화된 각각의 단어 벡터라고 볼 수 있습니다.\n",
    "<br>\n",
    "\n",
    "이 문서 벡터들과 단어 벡터들을 통해 다른 문서의 유사도, 다른 단어의 유사도, 단어(쿼리)로부터 문서의 유사도를 구하는 것들이 가능해집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47RWIj59cTpJ"
   },
   "source": [
    "### 6.3.1 LSA를 이용한 차원 축소와 성능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CdSq-LbncTpJ",
    "outputId": "e499a760-4434-45b3-99f7-c8655a3f7ae7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_916722/3437677460.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#압축할 component의 수 지정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train_lsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### ... 이 부분을 완성하시오\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_test_lsa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2000, random_state=7) #압축할 component의 수 지정\n",
    "\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf) ### ... 이 부분을 완성하시오\n",
    "X_test_lsa = svd.transform(X_test_tfidf)\n",
    "\n",
    "print('LSA Converted X shape:', X_train_lsa.shape)\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "LR_clf.fit(X_train_lsa, y_train) ### ... 이 부분을 완성하시오\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_lsa, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_lsa, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fj3fEpEZcTpJ",
    "outputId": "1f8cbe95-1235-4638-e475-509df28edbe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA Converted X shape: (2034, 100)\n",
      "Sum of explained variance ratio: 0.209\n",
      "#Train set score: 0.810\n",
      "#Test set score: 0.745\n"
     ]
    }
   ],
   "source": [
    "# 100차원으로 압축해보기\n",
    "svd = TruncatedSVD(n_components=100, random_state=1) ### ... 이 부분을 완성하시오\n",
    "\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "X_test_lsa = svd.transform(X_test_tfidf)\n",
    "\n",
    "print('LSA Converted X shape:', X_train_lsa.shape)\n",
    "print('Sum of explained variance ratio: {:.3f}'.format(svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "LR_clf.fit(X_train_lsa, y_train)\n",
    "print('#Train set score: {:.3f}'.format(LR_clf.score(X_train_lsa, y_train)))\n",
    "print('#Test set score: {:.3f}'.format(LR_clf.score(X_test_lsa, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWic08h5cTpJ"
   },
   "source": [
    "### 6.3.2 LSA를 이용한 의미 기반의 문서 간 유사도 계산\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnPtaCVCnxGb"
   },
   "source": [
    "문서1 : 저는 사과 좋아요\n",
    "문서2 : 저는 바나나 좋아요\n",
    "문서3 : 저는 바나나 좋아요 저는 바나나 좋아요\n",
    "\n",
    "띄어쓰기 기준 토큰화를 진행했다고 가정했을 때, 위의 세 문서에 대한 문서-단어 행렬\n",
    "\n",
    "| 문서 / 단어 | 저는 | 사과 | 좋아요 | 바나나 |\n",
    "|:--------:|:---:|:---:|:-----:|:----:|\n",
    "| **문서1**  |  1  |  1  |   1   |   0   |\n",
    "| **문서2**  |  1  |  0  |   1   |   1   |\n",
    "| **문서3**  |  2  |  0  |   2   |   2   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1ZM_XP9n8is"
   },
   "source": [
    "Numpy를 사용해서 코사인 유사도를 계산하는 방법\n",
    "* cos_sim(A, B) 함수를 구현하고 각 문서 벡터 간의 코사인 유사도를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ucsQAShInwSU",
    "outputId": "4d8b0283-96bb-495a-df02-63c6f3cc20b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1과 문서2의 유사도 : 0.6666666666666667\n",
      "문서 1과 문서3의 유사도 : 0.6666666666666667\n",
      "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cos_sim(A, B):\n",
    "    return dot(A, B)/(norm(A)*norm(B)) ### ... 이 부분을 완성하시오\n",
    "\n",
    "doc1 = np.array([0,1,1,1])\n",
    "doc2 = np.array([1,0,1,1])\n",
    "doc3 = np.array([2,0,2,2])\n",
    "\n",
    "print('문서 1과 문서2의 유사도 :',cos_sim(doc1, doc2))\n",
    "print('문서 1과 문서3의 유사도 :',cos_sim(doc1, doc3))\n",
    "print('문서 2와 문서3의 유사도 :',cos_sim(doc2, doc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns1Ha8kGoD0G"
   },
   "source": [
    "sklearn의 cosine_similarity 를 이용하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBQi58JCnwUM",
    "outputId": "ad17699c-51f6-4ac0-fd17-9673ac5534ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 1과 문서2의 유사도 : 0.6666666666666669\n",
      "문서 1과 문서3의 유사도 : 0.6666666666666669\n",
      "문서 2와 문서3의 유사도 : 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# DTM 정의\n",
    "doc1 = np.array([[0,1,1,1]])\n",
    "doc2 = np.array([[1,0,1,1]])\n",
    "doc3 = np.array([[2,0,2,2]])\n",
    "\n",
    "# cosine_similarity를 사용하여 유사도 계산\n",
    "sim12 = cosine_similarity(doc1, doc2)\n",
    "sim13 = cosine_similarity(doc1, doc3)\n",
    "sim23 = cosine_similarity(doc2, doc3)\n",
    "\n",
    "print('문서 1과 문서2의 유사도 :', sim12[0][0])\n",
    "print('문서 1과 문서3의 유사도 :', sim13[0][0])\n",
    "print('문서 2와 문서3의 유사도 :', sim23[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2EeedmClvLB"
   },
   "source": [
    "### LSA 벡터 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgd0IR_lcTpJ",
    "outputId": "1b1b1720-87b5-49c1-ca48-95761e0bb7e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#사용된 전체 카테고리: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "#첫 문서의 카테고리: 1\n",
      "#첫 문서의 내용: Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "#Top 20 유사도(lsa):\n",
      " [1.0, 0.74, 0.74, 0.72, 0.7, 0.7, 0.69, 0.67, 0.66, 0.65, 0.65, 0.65, 0.63, 0.62, 0.62, 0.62, 0.57, 0.57, 0.55, 0.54]\n",
      "#Top 20 유사 뉴스의 인덱스(lsa):\n",
      " [   0 1957 1674  501 1995 1490  790 1902 1575 1209 1728  892 1892  998\n",
      " 1038 1826 1290 1089  867  151]\n",
      "#Top 20 유사 뉴스의 카테고리(lsa):\n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print('#사용된 전체 카테고리:', newsgroups_train.target_names)\n",
    "print('#첫 문서의 카테고리:', y_train[0])\n",
    "\n",
    "print('#첫 문서의 내용:', X_train[0])\n",
    "\n",
    "#변환된 count vector와 기존 값들과의 similarity 계산\n",
    "sim_result = cosine_similarity([X_train_lsa[0]], X_train_lsa) ### ... 이 부분을 완성하시오\n",
    "\n",
    "print(\"#Top 20 유사도(lsa):\\n\", sorted(sim_result[0].round(2), reverse=True)[:20])\n",
    "sim_index = (-sim_result[0]).argsort()[:20]\n",
    "print('#Top 20 유사 뉴스의 인덱스(lsa):\\n', sim_index)\n",
    "sim_labels = [y_train[i] for i in sim_index]\n",
    "print('#Top 20 유사 뉴스의 카테고리(lsa):\\n', sim_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6To4eJ5llsLt"
   },
   "source": [
    "### TF-IDF 벡터 유사도 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZVBxkrzcTpJ",
    "outputId": "1f194f7b-14c9-45a0-ffa9-f94572d35a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Top 20 유사도(tfidf):\n",
      " [1.0, 0.3, 0.22, 0.21, 0.19, 0.19, 0.19, 0.17, 0.16, 0.16, 0.16, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.15, 0.14]\n",
      "#Top 20 유사 뉴스의 인덱스(tfidf):\n",
      " [   0 1575 1892 1490  501 1290 1013  998 1636 1705 1995 1957 1664  651\n",
      " 1038  429 1089 1209 1728 1803]\n",
      "#Top 20 유사 뉴스의 카테고리(tfidf):\n",
      " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
    "\n",
    "# 유사도가 높은 순으로 정렬\n",
    "print(\"#Top 20 유사도(tfidf):\\n\", sorted(sim_result[0].round(2), reverse=True)[:20]) ### ... 이 부분을 완성하시오\n",
    "\n",
    "# 유사도가 높은 순으로 정렬 후, 해당 값의 index를 반환\n",
    "sim_index = (-sim_result[0]).argsort()[:20] ### ... 이 부분을 완성하시오\n",
    "print('#Top 20 유사 뉴스의 인덱스(tfidf):\\n', sim_index)\n",
    "sim_labels = [y_train[i] for i in sim_index]\n",
    "print('#Top 20 유사 뉴스의 카테고리(tfidf):\\n', sim_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzC4y3peu7oq"
   },
   "source": [
    "## 7-1 주차 수업 내용 -끝-\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFkQNW24z-eI"
   },
   "source": [
    "# [[실습 7-1-1]] 유사도를 이용한 영화 추천 시스템 구현하기: TF-IDF 벡터 vs LSA 벡터\n",
    "영화 소개, 제목, 평점 등이 있는 **'movies_metadata.csv'** 데이터 셋을 이용하여, 특정 영화와 가장 유사한 영화를 찾아 추천해주기\n",
    "\n",
    "* 영화 소개(overview)에 대한 내용을 각각 TF-IDF 벡터로도 나타내보고, LSA로도 나타내보기\n",
    "* 유사한 영화에 자기 자신을 포함할 수 있음. 가능한 경우, 이를 따로 처리해도 좋고 처리하지 않아도 됨\n",
    "* Dataset: https://www.kaggle.com/rounakbanik/the-movies-dataset\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### [제출 내용]\n",
    "\n",
    "1.   TF-IDF를 이용하여, 영화 소개(overview)의 내용이 가장 유사한 영화(title) 5개를 찾는 코드 작성\n",
    "    \n",
    "2.   LSA를 이용하여, 영화 소개(overview)의 내용이 가장 유사한 영화(title) 5개를 찾는 코드 작성\n",
    "3.   TF-IDF와 LSA의 결과 비교 설명. LSA가 의미를 더 잘 찾는 것 같은지? 자신에게는 TF-IDF와 LSA 중 어떤 것이 더 마음에 드는 방법이었는지 결론을 내려보기\n",
    "    * 유사도, 영화 소개의 내용, average_vote (평점) 등을 참고하여 비교해 보시오.\n",
    "\n",
    "\n",
    "### [참고 코드]\n",
    "* **참고용**으로 사용하시면 됩니다. 더 편한 방법이 있다면 해당 방법으로 작성하셔도 좋습니다.\n",
    "* 참고 코드는 0번째 영화 & TF-IDF에 대해서만 작성되어 있음\n",
    "    * 0번째 영화가 아닌 다른 n번째 영화를 선택하여 비교해보아도 좋습니다.\n",
    "    * **(주의!)** LSA에 대한 코드를 추가 작성해야 합니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./movies_metadata.csv', encoding='utf-8', low_memory=False)\n",
    "df.head(5)\n",
    "```\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 평점이 8점 이상인 영화 중에서 추천\n",
    "sampled_df = df[df['vote_average'] >= 8].reset_index(drop=True)\n",
    "sampled_df.shape\n",
    "```\n",
    "\n",
    "```\n",
    "# overview에 빈 값이 있는 경우, ''로 채우기\n",
    "sampled_df['overview'] = sampled_df['overview'].fillna('')\n",
    "```\n",
    "\n",
    "```\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampled_df.overview, sampled_df.title, random_state=0)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "```\n",
    "```\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"0번째 영화 제목\\n\", y_train[0])\n",
    "print(\"0번째 영화 소개 내용\\n\", X_train[0])\n",
    "\n",
    "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
    "\n",
    "print(\"#Top 5 유사도(tfidf):\\n\", sorted(sim_result[0].round(2), reverse=True)[:5])\n",
    "sim_index = (-sim_result[0]).argsort()[:5]\n",
    "```\n",
    "```\n",
    "result_df = pd.DataFrame({\n",
    "    '유사도': sorted(sim_result[0].round(2), reverse=True)[:5],\n",
    "    '인덱스': sim_index,\n",
    "    '제목': [sampled_df.title[i] for i in sim_index],\n",
    "    '영화 소개': [sampled_df.overview[i] for i in sim_index],\n",
    "    '평점': [sampled_df.vote_average[i] for i in sim_index]\n",
    "})\n",
    "\n",
    "result_df\n",
    "```\n",
    "```\n",
    "X_train_tfidf.shape\n",
    "```\n",
    "```\n",
    "print('TF-IDF 기반으로 계산한 결과 추천하는 영화는: ', [sampled_df.title[i] for i in sim_index][:1])\n",
    "```\n",
    "* ### 위의 참고 코드를 복사 붙여넣기하여 시작해보시면 도움이 될 것 같습니다.\n",
    "* ### 아래에 코드 또는 텍스트를 추가하여 작성하시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4kXNz3cbe00"
   },
   "source": [
    "1.   TF-IDF를 이용하여, 영화 소개(overview)의 내용이 가장 유사한 영화(title) 5개를 찾는 코드 작성\n",
    "    \n",
    "2.   LSA를 이용하여, 영화 소개(overview)의 내용이 가장 유사한 영화(title) 5개를 찾는 코드 작성\n",
    "3.   TF-IDF와 LSA의 결과 비교 설명. LSA가 의미를 더 잘 찾는 것 같은지? 자신에게는 TF-IDF와 LSA 중 어떤 것이 더 마음에 드는 방법이었는지 결론을 내려보기\n",
    "    * 유사도, 영화 소개의 내용, average_vote (평점) 등을 참고하여 비교해 보시오.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "dbNAqdw6bblL",
    "outputId": "b4941f07-fb0e-4221-d3b1-4364a74d6c28"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './movies_metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_916722/924629034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./movies_metadata.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    863\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 865\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    866\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './movies_metadata.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./movies_metadata.csv', encoding='utf-8', low_memory=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlco8qIQSir9",
    "outputId": "abfeabfa-8bc2-46af-ba07-141331bf850b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1895, 24)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 평점이 8점 이상인 영화 중에서 추천\n",
    "sampled_df = df[df['vote_average'] >= 8].reset_index(drop=True)\n",
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "j9sfe0WwTNNO"
   },
   "outputs": [],
   "source": [
    "# overview에 빈 값이 있는 경우, ''로 채우기\n",
    "sampled_df['overview'] = sampled_df['overview'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dh5p1dNZ5gHu"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "x0FU9LGLTRV9"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tAomECKITqqq",
    "outputId": "2a35ec89-66e4-4ec2-f6d5-fa5662ac347a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Two homicide detectives are on a desperate hun...\n",
       "1       Held in an L.A. interrogation room, Verbal Kin...\n",
       "2       A mentally unstable Vietnam War veteran works ...\n",
       "3       On Christmas eve, a relentlessly cheerful woma...\n",
       "4       Princess Leia is captured and held hostage by ...\n",
       "                              ...                        \n",
       "1890    Blurred images illustrate the narration of Hug...\n",
       "1891                                                     \n",
       "1892    Born in Los Angeles but a New Yorker by choice...\n",
       "1893    A closeted boy runs the risk of being outed by...\n",
       "1894    An artist struggles to finish his work while a...\n",
       "Name: overview, Length: 1895, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df_overview = sampled_df['overview']\n",
    "sampled_df_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "mZbLvshlVgqx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampled_df.overview, sampled_df.title, random_state=0)\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpdh_qc3ViQK",
    "outputId": "fcfeb6e1-59fc-45c1-c06f-23a4af09be9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 영화 제목\n",
      " Se7en\n",
      "0번째 영화 소개 내용\n",
      " Two homicide detectives are on a desperate hunt for a serial killer whose crimes are based on the \"seven deadly sins\" in this dark and haunting film that takes viewers from the tortured remains of one victim to the next. The seasoned Det. Sommerset researches each sin in an effort to get inside the killer's mind, while his novice partner, Mills, scoffs at his efforts to unravel the case.\n",
      "#Top 5 유사도(tfidf):\n",
      " [1.0, 0.27, 0.26, 0.23, 0.23]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"0번째 영화 제목\\n\", y_train[0])\n",
    "print(\"0번째 영화 소개 내용\\n\", X_train[0])\n",
    "\n",
    "sim_result = cosine_similarity(X_train_tfidf[0], X_train_tfidf)\n",
    "\n",
    "print(\"#Top 5 유사도(tfidf):\\n\", sorted(sim_result[0].round(2), reverse=True)[:5])\n",
    "sim_index = (-sim_result[0]).argsort()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "tuII_m0oWE0t",
    "outputId": "b12730bf-c87b-4dd5-ce41-be1fc21b9675"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-cb09d787-3288-481c-927e-e6979f95be20\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>유사도</th>\n",
       "      <th>인덱스</th>\n",
       "      <th>제목</th>\n",
       "      <th>영화 소개</th>\n",
       "      <th>평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Se7en</td>\n",
       "      <td>Two homicide detectives are on a desperate hun...</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pin Boy</td>\n",
       "      <td>A country boy tries to find his place in Bueno...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.26</td>\n",
       "      <td>1130</td>\n",
       "      <td>Karachi se Lahore</td>\n",
       "      <td>A road trip from Karachi to Lahore where 5 fri...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1399</td>\n",
       "      <td>Houston, We Have a Problem!</td>\n",
       "      <td>The cold war, the space race, and NASA’s moon ...</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1003</td>\n",
       "      <td>Pudhupettai</td>\n",
       "      <td>The story is set in the backdrop of the slums ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb09d787-3288-481c-927e-e6979f95be20')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-cb09d787-3288-481c-927e-e6979f95be20 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-cb09d787-3288-481c-927e-e6979f95be20');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-9b58d994-8a3c-4261-ba29-bdfa4ef80d71\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9b58d994-8a3c-4261-ba29-bdfa4ef80d71')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-9b58d994-8a3c-4261-ba29-bdfa4ef80d71 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    유사도   인덱스                           제목  \\\n",
       "0  1.00     0                        Se7en   \n",
       "1  0.27  1301                      Pin Boy   \n",
       "2  0.26  1130            Karachi se Lahore   \n",
       "3  0.23  1399  Houston, We Have a Problem!   \n",
       "4  0.23  1003                  Pudhupettai   \n",
       "\n",
       "                                               영화 소개    평점  \n",
       "0  Two homicide detectives are on a desperate hun...   8.1  \n",
       "1  A country boy tries to find his place in Bueno...  10.0  \n",
       "2  A road trip from Karachi to Lahore where 5 fri...   8.0  \n",
       "3  The cold war, the space race, and NASA’s moon ...   8.7  \n",
       "4  The story is set in the backdrop of the slums ...   8.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    '유사도': sorted(sim_result[0].round(2), reverse=True)[:5],\n",
    "    '인덱스': sim_index,\n",
    "    '제목': [sampled_df.title[i] for i in sim_index],\n",
    "    '영화 소개': [sampled_df.overview[i] for i in sim_index],\n",
    "    '평점': [sampled_df.vote_average[i] for i in sim_index]\n",
    "})\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kK7KFSNnPQ9c",
    "outputId": "438207f5-83a7-4827-9cf6-f0f4fd1c46a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 기반으로 계산한 결과 추천하는 영화는:  ['Se7en', 'Pin Boy', 'Karachi se Lahore', 'Houston, We Have a Problem!', 'Pudhupettai']\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF 기반으로 계산한 결과 추천하는 영화는: ', [sampled_df.title[i] for i in sim_index][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFYEyEHrWKYK",
    "outputId": "16d2aa5a-b6b1-4202-c159-d125cabaf944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "상위 5개의 유사도를 가진 인덱스: [   0 1301 1044 1399  914]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components = 100,random_state=7)\n",
    "X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "sim_result = cosine_similarity([X_train_lsa[0]], X_train_lsa)\n",
    "highest_idx = (-sim_result[0]).argsort()[:5]\n",
    "print(\"상위 5개의 유사도를 가진 인덱스:\",highest_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "oTounzk_MyW-",
    "outputId": "62e45b79-cd31-4f6a-fa0e-ec4822c9fa46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-07868dc3-cac8-4b8d-815c-6b9e465d1096\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>유사도</th>\n",
       "      <th>인덱스</th>\n",
       "      <th>제목</th>\n",
       "      <th>영화 소개</th>\n",
       "      <th>평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>Se7en</td>\n",
       "      <td>Two homicide detectives are on a desperate hun...</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.65</td>\n",
       "      <td>1301</td>\n",
       "      <td>Pin Boy</td>\n",
       "      <td>A country boy tries to find his place in Bueno...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1044</td>\n",
       "      <td>The Dream Team</td>\n",
       "      <td>The world had rarely seen a frenzy as the one ...</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>1399</td>\n",
       "      <td>Houston, We Have a Problem!</td>\n",
       "      <td>The cold war, the space race, and NASA’s moon ...</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.55</td>\n",
       "      <td>914</td>\n",
       "      <td>One Last Hug</td>\n",
       "      <td>\"One Last Hug\" chronicles a three day summer c...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07868dc3-cac8-4b8d-815c-6b9e465d1096')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-07868dc3-cac8-4b8d-815c-6b9e465d1096 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-07868dc3-cac8-4b8d-815c-6b9e465d1096');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-87fc9733-b172-46f7-911e-6bf2b78352a1\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-87fc9733-b172-46f7-911e-6bf2b78352a1')\"\n",
       "            title=\"Suggest charts.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-87fc9733-b172-46f7-911e-6bf2b78352a1 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    유사도   인덱스                           제목  \\\n",
       "0  1.00     0                        Se7en   \n",
       "1  0.65  1301                      Pin Boy   \n",
       "2  0.61  1044               The Dream Team   \n",
       "3  0.60  1399  Houston, We Have a Problem!   \n",
       "4  0.55   914                 One Last Hug   \n",
       "\n",
       "                                               영화 소개    평점  \n",
       "0  Two homicide detectives are on a desperate hun...   8.1  \n",
       "1  A country boy tries to find his place in Bueno...  10.0  \n",
       "2  The world had rarely seen a frenzy as the one ...   8.3  \n",
       "3  The cold war, the space race, and NASA’s moon ...   8.7  \n",
       "4  \"One Last Hug\" chronicles a three day summer c...   8.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    '유사도': sorted(sim_result[0].round(2), reverse=True)[:5],\n",
    "    '인덱스': highest_idx,\n",
    "    '제목': [sampled_df.title[i] for i in highest_idx],\n",
    "    '영화 소개': [sampled_df.overview[i] for i in highest_idx],\n",
    "    '평점': [sampled_df.vote_average[i] for i in highest_idx]\n",
    "})\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQSfy-dRPaSP",
    "outputId": "e88ffec1-b093-4f42-f5a4-520a70a33ff7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF 기반으로 계산한 결과 추천하는 영화는:  ['Se7en', 'Pin Boy', 'The Dream Team', 'Houston, We Have a Problem!', 'One Last Hug']\n"
     ]
    }
   ],
   "source": [
    "print('TF-IDF 기반으로 계산한 결과 추천하는 영화는: ', [sampled_df.title[i] for i in highest_idx][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tBSVvewPjA-"
   },
   "source": [
    "2번 인덱스와 4번 인덱스가 다른 영향을 갖는다고 나왔다. 또한 유사도를 측정했을때, n_components를 100으로 설정해서 그런지 유사도가 TF-IDF를 2000으로 측정했을때에 비해 유사도가 상당히 높게 나왔다. 이는 유니크한 단어가 영화소개에 상당히 많았는데 이를 제거해서 유사도가 높게 나온 것이고, 따라서 n_components를 극단으로 낮추는 것은 오히려 안좋은 결과를 내는 것으로 보인다. 따라서 나는 컴퓨팅 자원이 충분하다면 과적합이 일어나지 않는 선에서 TF-IDF를 선호할 것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esH2v6SMu-gg"
   },
   "source": [
    "# [파일] -> [다운로드] -> [.ipynb 다운로드]\n",
    "# 제출 후 **구글 계정 로그아웃** 잘 하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Qc3oIZgMu-x"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
